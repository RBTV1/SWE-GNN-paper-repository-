{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e06c7e93-c131-440f-bc58-4057ef9787f5",
   "metadata": {},
   "source": [
    "# Convert raw dataset into pytorch geometric dataset and save them\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8c6e144-a5b9-4543-9216-6da57827aeb9",
   "metadata": {},
   "source": [
    "## Graph creation\n",
    "\n",
    "The generation, conversion, and storage of grid-based graph datasets for Graph Neural Networks (GNNs), specifically tailored for PyTorch Geometric (PyG). Its applications are envisioned in environmental simulations like terrain modeling or flood prediction, where the spatial arrangement and attributes are crucial.\n",
    "\n",
    "### Function Descriptions\n",
    "\n",
    "- **`center_grid_graph(dim1, dim2)`**:  \n",
    "    Creates a directed graph from a rectangular grid of specified dimensions, where each grid cell represents a node. Edges connect adjacent nodes to model spatial continuity. Nodes are placed at the centers of grid cells, establishing the spatial structure for environmental modeling.\n",
    "\n",
    "- **`get_coords(pos)`**:  \n",
    "    Extracts x and y coordinates of each node from a position dictionary and returns them in a NumPy array. This utility is useful for numerical operations involving node positions, such as distance calculations.\n",
    "\n",
    "- **`get_corners(pos)`** and **`get_contour(pos)`**:  \n",
    "    These functions compute the coordinates of the grid's corners and its contour. Such utilities are helpful for tasks requiring awareness of spatial boundaries or the grid's external shape.\n",
    "\n",
    "- **`reorder_dict(dictt)`**:  \n",
    "    Reorganizes a dictionary by its values, assigning new sequential numeric keys. This simplifies data access and ensures consistency when working with graph attributes.\n",
    "\n",
    "- **`convert_to_pyg(graph, pos, DEM, WD, VX, VY)`**:  \n",
    "    Converts a graph into a PyTorch Geometric `Data` object, incorporating spatial and environmental attributes like elevation (DEM) and water depth (WD). This conversion is crucial for enabling GNNs to learn from physically relevant patterns.\n",
    "\n",
    "- **`create_grid_dataset(dataset_folder, n_sim, start_sim=1, number_grids=64)`**:  \n",
    "    Automates the loading of simulation data, generating a dataset of `Data` objects. This function streamlines the preparation of datasets for GNN model training or testing.\n",
    "\n",
    "- **`save_database(dataset, name, out_path='datasets')`**:  \n",
    "    Saves the generated dataset to disk using pickle serialization. This ensures the dataset can be easily retrieved for future use.\n",
    "\n",
    "- **`create_dataset_folders(dataset_folder='datasets')`**:  \n",
    "    Prepares the directory structure for dataset storage, with separate folders for training and testing data. This organization aids in dataset management.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cd64e9d2-5ea3-4570-867e-eafde231f13e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import networkx as nx\n",
    "import os\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "\n",
    "def center_grid_graph(dim1, dim2):\n",
    "    '''\n",
    "    Create graph from a rectangular grid of dimensions dim1 x dim2\n",
    "    Returns networkx graph connecting the grid centers and corresponding \n",
    "    node positions\n",
    "    ------\n",
    "    dim1: int\n",
    "        number of grids in the x direction\n",
    "    dim2: int\n",
    "        number of grids in the y direction\n",
    "    '''\n",
    "    G = nx.grid_2d_graph(dim1, dim2, create_using=nx.DiGraph)\n",
    "    # for the position, it is assumed that they are located in the centre of each grid\n",
    "    pos = {i:(x+0.5,y+0.5) for i, (x,y) in enumerate(G.nodes())}\n",
    "    \n",
    "    #change keys from (x,y) format to i format\n",
    "    mapping = dict(zip(G, range(0, G.number_of_nodes())))\n",
    "    G = nx.relabel_nodes(G, mapping)\n",
    "\n",
    "    return G, pos\n",
    "\n",
    "def get_coords(pos):\n",
    "    '''\n",
    "    Returns array of dimensions (n_nodes, 2) containing x and y coordinates of each node\n",
    "    ------\n",
    "    pos: dict\n",
    "        keys: (x,y) index of every node\n",
    "        values: spatial x and y positions of each node\n",
    "    '''\n",
    "    return np.array([xy for xy in pos.values()])\n",
    "\t\n",
    "\n",
    "def get_corners(pos):\n",
    "    '''\n",
    "    Returns the coordinates of the corners of a grid\n",
    "    ------\n",
    "    pos: dict\n",
    "        keys: (x,y) index of every node\n",
    "        values: spatial x and y positions of each node\n",
    "    '''    \n",
    "    BL = min(pos.values()) #bottom-left\n",
    "    TR = max(pos.values()) #top-right\n",
    "    BR = (BL[0], TR[1]) #bottom-right\n",
    "    TL = (TR[0], BL[1]) #top-left\n",
    "    \n",
    "    return BL, TR, BR, TL\n",
    "\n",
    "def get_contour(pos):\n",
    "    '''\n",
    "    Returns a dictionary with the contours of a grid\n",
    "    ------\n",
    "    pos: dict\n",
    "        keys: (x,y) index of every node\n",
    "        values: spatial x and y positions of each node\n",
    "    '''\n",
    "    BL, TR, BR, TL = get_corners(pos)\n",
    "    \n",
    "    x_pos = np.arange(BL[0], TR[0]+1)\n",
    "    y_pos = np.arange(BL[1], TR[1]+1)\n",
    "    \n",
    "    bottom = [(x, BL[1]) for x in x_pos]\n",
    "    left = [(BL[0], y) for y in y_pos]\n",
    "    right = [(TR[0], y) for y in y_pos]\n",
    "    top = [(x, TR[1]) for x in x_pos]\n",
    "    \n",
    "    contour = {}\n",
    "\n",
    "    for point in (bottom + left + right + top):\n",
    "        key = list(pos.keys())[list(pos.values()).index(point)]\n",
    "        contour[point] = pos[key]\n",
    "    \n",
    "    return contour\n",
    "\n",
    "def reorder_dict(dictt):\n",
    "    '''\n",
    "    Change the key of a dictionary and sorts it by values order\n",
    "    '''\n",
    "    new_dict = {}\n",
    "    \n",
    "    #sort to exclude double values and order it\n",
    "    dictt = dict(sorted(dictt.items()))\n",
    "\n",
    "    #change keys from (x,y) format to i format\n",
    "    for i, key in enumerate(dictt.keys()):\n",
    "        new_dict[i] = dictt[key]\n",
    "        \n",
    "    return new_dict\n",
    "\n",
    "def convert_to_pyg(graph, pos, DEM, WD, VX, VY):\n",
    "    '''Converts a graph or mesh into a PyTorch Geometric Data type \n",
    "    Then, add position, DEM, and water variables to data object'''\n",
    "    DEM = DEM.reshape(-1)\n",
    "\n",
    "    edge_index = torch.LongTensor(list(graph.edges)).t().contiguous()\n",
    "    row, col = edge_index\n",
    "\n",
    "    data = Data()\n",
    "\n",
    "    delta_DEM = torch.FloatTensor(DEM[col]-DEM[row])\n",
    "    coords = torch.FloatTensor(get_coords(pos))\n",
    "    edge_relative_distance = coords[col] - coords[row]\n",
    "    edge_distance = torch.norm(edge_relative_distance, dim=1)\n",
    "    edge_slope = delta_DEM/edge_distance\n",
    "\n",
    "    data.edge_index = edge_index\n",
    "    data.edge_distance = edge_distance\n",
    "    data.edge_slope = edge_slope\n",
    "    data.edge_relative_distance = edge_relative_distance\n",
    "\n",
    "    data.num_nodes = graph.number_of_nodes()\n",
    "    data.pos = torch.tensor(list(pos.values()))\n",
    "    data.DEM = torch.FloatTensor(DEM)\n",
    "    data.WD = torch.FloatTensor(WD.T)\n",
    "    data.VX = torch.FloatTensor(VX.T)\n",
    "    data.VY = torch.FloatTensor(VY.T)\n",
    "        \n",
    "    return data\n",
    "\n",
    "def create_grid_dataset(dataset_folder, n_sim, start_sim=1, number_grids=64):\n",
    "    assert os.path.exists(dataset_folder), \"There is no raw dataset folder\"\n",
    "    grid_dataset = []\n",
    "\n",
    "    graph, pos = center_grid_graph(number_grids,number_grids)\n",
    "    \n",
    "    for i in tqdm(range(start_sim, start_sim + n_sim)):\n",
    "        DEM_path = os.path.join(dataset_folder, \"DEM\", f\"DEM_{i}.txt\")\n",
    "        WD_path = os.path.join(dataset_folder, \"WD\", f\"WD_{i}.txt\")\n",
    "        VX_path = os.path.join(dataset_folder, \"VX\", f\"VX_{i}.txt\")\n",
    "        VY_path = os.path.join(dataset_folder, \"VY\", f\"VY_{i}.txt\")\n",
    "\n",
    "        DEM = np.loadtxt(DEM_path)[:, 2]\n",
    "        WD = np.loadtxt(WD_path)\n",
    "        VX = np.loadtxt(VX_path)\n",
    "        VY = np.loadtxt(VY_path)\n",
    "        \n",
    "        grid_i = convert_to_pyg(graph, pos, DEM, WD, VX, VY)\n",
    "        grid_dataset.append(grid_i)\n",
    "    \n",
    "    return grid_dataset\n",
    "\n",
    "\n",
    "def save_database(dataset, name, out_path='datasets'):\n",
    "    '''\n",
    "    This function saves the geometric database into a pickle file\n",
    "    The name of the file is given by the type of graph and number of simulations\n",
    "    ------\n",
    "    dataset: list\n",
    "        list of geometric datasets for grid and mesh\n",
    "    names: str\n",
    "        name of saved dataset\n",
    "    out_path: str, path-like\n",
    "        output file location\n",
    "    '''\n",
    "    n_sim = len(dataset)\n",
    "    path = f\"{out_path}/{name}.pkl\"\n",
    "    \n",
    "    if os.path.exists(path):\n",
    "        os.remove(path)\n",
    "    elif not os.path.exists(out_path):\n",
    "        os.mkdir(out_path)\n",
    "    \n",
    "    pickle.dump(dataset, open(path, \"wb\" ))\n",
    "        \n",
    "    return None\n",
    "\n",
    "def create_dataset_folders(dataset_folder='datasets'):\n",
    "    if not os.path.exists(dataset_folder):\n",
    "        os.makedirs(dataset_folder)\n",
    "\n",
    "    train_folder = os.path.join(dataset_folder, 'train')\n",
    "    test_folder = os.path.join(dataset_folder, 'test')\n",
    "\n",
    "    if not os.path.exists(train_folder):\n",
    "        os.makedirs(train_folder)\n",
    "\n",
    "    if not os.path.exists(test_folder):\n",
    "        os.makedirs(test_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dd7837d-1956-46e8-a9b3-b2bb8359597f",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### Workflow Overview\n",
    "\n",
    "1. **Simulation IDs Definition**:  \n",
    "    - A list named `simulation_ids` is initialized, defining various simulation parameters. Each entry specifies the dataset type (e.g., `grid`, `random_breach_grid`), the directory for saving the dataset (`datasets/train` or `datasets/test`), the starting simulation ID, the number of simulations to generate, and the grid dimensions.\n",
    "\n",
    "2. **Dataset Folder Preparation**:  \n",
    "    - The `create_dataset_folders` function is called to ensure the appropriate directory structure exists within a base `datasets` folder. This structure includes separate subdirectories for training and testing datasets.\n",
    "\n",
    "3. **Path Debugging**:  \n",
    "    - A debug print statement confirms the absolute path for a DEM file, helping to verify the correct directory structure and file naming convention.\n",
    "\n",
    "4. **Dataset Generation and Saving**:  \n",
    "    - The script iterates over each entry in `simulation_ids`, generating and saving datasets according to the specified parameters. The `create_grid_dataset` function is tasked with creating a PyG dataset for each simulation range, incorporating spatial and environmental data from text files. Following dataset creation, the `save_database` function serializes and saves the dataset to the specified directory.\n",
    "\n",
    "### Key Functions\n",
    "\n",
    "- **`create_grid_dataset`**: Automates the creation of grid-based datasets from specified simulation parameters, loading environmental data and structuring it into a format suitable for GNNs.\n",
    "- **`save_database`**: Serializes and saves the generated PyG datasets, facilitating easy access for future model training and evaluation.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28e4bfe6-9e5f-4cd9-b58e-5e61abbd6711",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the dataset folder path\n",
    "dataset_folder = '/home/jupyter/SWE-GNN-paper-repository-/database/raw_datasets'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d441629-2d49-4a41-9c35-7a9d5a038762",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define simulation IDs\n",
    "simulation_ids = [\n",
    "    ['grid', 'datasets/train', 1, 80, 64],\n",
    "    ['grid', 'datasets/test', 500, 20, 64],\n",
    "    ['random_breach_grid', 'datasets/test', 10001, 20, 64],\n",
    "    ['big_random_breach_grid', 'datasets/test', 15001, 10, 128],\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73493412-ca65-43d7-992d-d8dd84f82a54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataset folders\n",
    "create_dataset_folders(dataset_folder='datasets')\n",
    "\n",
    "# Debugging the path\n",
    "print(os.path.abspath(os.path.join(dataset_folder, \"DEM\", \"DEM_1.txt\")))\n",
    "\n",
    "for dataset_name, dataset_dir, start_sim_id, n_sim, n_grids in simulation_ids:\n",
    "    pyg_dataset = create_grid_dataset(dataset_folder, n_sim=n_sim, start_sim=start_sim_id, number_grids=n_grids)\n",
    "    save_database(pyg_dataset, name=dataset_name, out_path=dataset_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29ff7162-a459-4ad2-9c61-21a2fe69ac1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This is how a sample of the dataset will look like:\n",
    "pyg_dataset[0]"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-env-pytorch-pytorch",
   "name": "workbench-notebooks.m115",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/workbench-notebooks:m115"
  },
  "kernelspec": {
   "display_name": "PyTorch 1-13 (Local)",
   "language": "python",
   "name": "conda-env-pytorch-pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
